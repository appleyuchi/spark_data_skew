设置方法可以是：
①$SPARK_HOME/conf的配置文件spark-env.sh中修改
spark.sql.shuffle.partitions
spark.default.parallelism

②val spark =SparkSession.builder().
appName("spark_skew_test").
master("local[2]").config("spark.default.
parallelism",defPar).getOrCreate();

③spark-shell下面(直接写入xxxByKey中,下面例子中groupByKey):
val scores = Array(("class1",95),("class2",85),("class1",75))
val scoreRDD=sc.parallelize(scores)
scoreRDD.groupByKey(3).collect.foreach(_._2.foreach(println))



④如果需要同时在算子中填写具体操作和并行度，示例如下:
val rdd2 = rdd1.reduceByKey(_+_,10)