①$SPARK_HOME/conf的配置文件spark-env.sh中修改
spark.sql.shuffle.partitions
spark.default.parallelism

②

import com.sun.rowset.internal.Row;
import org.apache.spark.SparkContext;
import org.apache.spark.api.java.JavaPairRDD;
import org.apache.spark.Partitioner;
import org.apache.spark.api.java.function.*;
import org.apache.spark.sql.SparkSession;
import scala.Tuple2;
import java.util.*;
import java.lang.*;
import org.apache.log4j.Logger;



public class parallel_improve
{

    public static void main(String[]  args) 
    {



Integer defPar=10;
SparkSession spark = SparkSession.builder().appName("spark_skew_test").master("local[2]").config("spark.default.parallelism", defPar).getOrCreate();
}

}


